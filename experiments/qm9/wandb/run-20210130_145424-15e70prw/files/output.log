

FLAGS: Namespace(batch_size=16, data_address='QM9_data.pt', device=device(type='cuda', index=0), div=2.0, fully_connected=False, head=8, log_interval=25, lr=0.001, model='SE3Transformer', name='qm9-homo', num_channels=32, num_degrees=4, num_epochs=100, num_layers=7, num_nlayers=0, num_workers=4, pooling='max', print_interval=250, profile=False, restore=None, save_dir='models', seed=1992, task='homo', wandb='equivariant-attention')
UNPARSED_ARGV: [] 


Loaded train-set, task: homo, source: QM9_data.pt, length: 100000
Loaded valid-set, task: homo, source: QM9_data.pt, length: 17748
Loaded test-set, task: homo, source: QM9_data.pt, length: 13083
ModuleList(
  (0): GSE3Res(
    (GMAB): ModuleDict(
      (v): GConvSE3Partial(structure=[(16, 0), (16, 1), (16, 2), (16, 3)])
      (k): GConvSE3Partial(structure=[(16, 0)])
      (q): G1x1SE3(structure=[(16, 0)])
      (attn): GMABSE3(n_heads=8, structure=[(16, 0), (16, 1), (16, 2), (16, 3)])
    )
    (cat): GCat(structure=[(22, 0), (16, 1), (16, 2), (16, 3)])
    (project): G1x1SE3(structure=[(32, 0), (32, 1), (32, 2), (32, 3)])
  )
  (1): GNormSE3(num_layers=0, nonlin=ReLU(inplace=True))
  (2): GSE3Res(
    (GMAB): ModuleDict(
      (v): GConvSE3Partial(structure=[(16, 0), (16, 1), (16, 2), (16, 3)])
      (k): GConvSE3Partial(structure=[(16, 0), (16, 1), (16, 2), (16, 3)])
      (q): G1x1SE3(structure=[(16, 0), (16, 1), (16, 2), (16, 3)])
      (attn): GMABSE3(n_heads=8, structure=[(16, 0), (16, 1), (16, 2), (16, 3)])
    )
    (cat): GCat(structure=[(48, 0), (48, 1), (48, 2), (48, 3)])
    (project): G1x1SE3(structure=[(32, 0), (32, 1), (32, 2), (32, 3)])
  )
  (3): GNormSE3(num_layers=0, nonlin=ReLU(inplace=True))
  (4): GSE3Res(
    (GMAB): ModuleDict(
      (v): GConvSE3Partial(structure=[(16, 0), (16, 1), (16, 2), (16, 3)])
      (k): GConvSE3Partial(structure=[(16, 0), (16, 1), (16, 2), (16, 3)])
      (q): G1x1SE3(structure=[(16, 0), (16, 1), (16, 2), (16, 3)])
      (attn): GMABSE3(n_heads=8, structure=[(16, 0), (16, 1), (16, 2), (16, 3)])
    )
    (cat): GCat(structure=[(48, 0), (48, 1), (48, 2), (48, 3)])
    (project): G1x1SE3(structure=[(32, 0), (32, 1), (32, 2), (32, 3)])
  )
  (5): GNormSE3(num_layers=0, nonlin=ReLU(inplace=True))
  (6): GSE3Res(
    (GMAB): ModuleDict(
      (v): GConvSE3Partial(structure=[(16, 0), (16, 1), (16, 2), (16, 3)])
      (k): GConvSE3Partial(structure=[(16, 0), (16, 1), (16, 2), (16, 3)])
      (q): G1x1SE3(structure=[(16, 0), (16, 1), (16, 2), (16, 3)])
      (attn): GMABSE3(n_heads=8, structure=[(16, 0), (16, 1), (16, 2), (16, 3)])
    )
    (cat): GCat(structure=[(48, 0), (48, 1), (48, 2), (48, 3)])
    (project): G1x1SE3(structure=[(32, 0), (32, 1), (32, 2), (32, 3)])
  )
  (7): GNormSE3(num_layers=0, nonlin=ReLU(inplace=True))
  (8): GSE3Res(
    (GMAB): ModuleDict(
      (v): GConvSE3Partial(structure=[(16, 0), (16, 1), (16, 2), (16, 3)])
      (k): GConvSE3Partial(structure=[(16, 0), (16, 1), (16, 2), (16, 3)])
      (q): G1x1SE3(structure=[(16, 0), (16, 1), (16, 2), (16, 3)])
      (attn): GMABSE3(n_heads=8, structure=[(16, 0), (16, 1), (16, 2), (16, 3)])
    )
    (cat): GCat(structure=[(48, 0), (48, 1), (48, 2), (48, 3)])
    (project): G1x1SE3(structure=[(32, 0), (32, 1), (32, 2), (32, 3)])
  )
  (9): GNormSE3(num_layers=0, nonlin=ReLU(inplace=True))
  (10): GSE3Res(
    (GMAB): ModuleDict(
      (v): GConvSE3Partial(structure=[(16, 0), (16, 1), (16, 2), (16, 3)])
      (k): GConvSE3Partial(structure=[(16, 0), (16, 1), (16, 2), (16, 3)])
      (q): G1x1SE3(structure=[(16, 0), (16, 1), (16, 2), (16, 3)])
      (attn): GMABSE3(n_heads=8, structure=[(16, 0), (16, 1), (16, 2), (16, 3)])
    )
    (cat): GCat(structure=[(48, 0), (48, 1), (48, 2), (48, 3)])
    (project): G1x1SE3(structure=[(32, 0), (32, 1), (32, 2), (32, 3)])
  )
  (11): GNormSE3(num_layers=0, nonlin=ReLU(inplace=True))
  (12): GSE3Res(
    (GMAB): ModuleDict(
      (v): GConvSE3Partial(structure=[(16, 0), (16, 1), (16, 2), (16, 3)])
      (k): GConvSE3Partial(structure=[(16, 0), (16, 1), (16, 2), (16, 3)])
      (q): G1x1SE3(structure=[(16, 0), (16, 1), (16, 2), (16, 3)])
      (attn): GMABSE3(n_heads=8, structure=[(16, 0), (16, 1), (16, 2), (16, 3)])
    )
    (cat): GCat(structure=[(48, 0), (48, 1), (48, 2), (48, 3)])
    (project): G1x1SE3(structure=[(32, 0), (32, 1), (32, 2), (32, 3)])
  )
  (13): GNormSE3(num_layers=0, nonlin=ReLU(inplace=True))
  (14): GConvSE3(structure=[(128, 0)], self_interaction=True)
  (15): GMaxPooling(
    (pool): MaxPooling()
  )
)
ModuleList(
  (0): Linear(in_features=128, out_features=128, bias=True)
  (1): ReLU(inplace=True)
  (2): Linear(in_features=128, out_features=1, bias=True)
)
Begin training
Saved: models/qm9-homo.pt
/home/vwslz/anaconda3/envs/ml/lib/python3.8/site-packages/torch/nn/modules/container.py:552: UserWarning: Setting attributes on ParameterDict is not supported.
  warnings.warn("Setting attributes on ParameterDict is not supported.")
/home/vwslz/anaconda3/envs/ml/lib/python3.8/site-packages/dgl/base.py:45: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  return warnings.warn(message, category=category, stacklevel=1)
/home/vwslz/anaconda3/envs/ml/lib/python3.8/site-packages/dgl/base.py:45: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  return warnings.warn(message, category=category, stacklevel=1)
/home/vwslz/anaconda3/envs/ml/lib/python3.8/site-packages/dgl/base.py:45: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  return warnings.warn(message, category=category, stacklevel=1)
/home/vwslz/anaconda3/envs/ml/lib/python3.8/site-packages/dgl/base.py:45: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  return warnings.warn(message, category=category, stacklevel=1)
compute 0.pkl.gz... save 0.pkl.gz... done
compute 1.pkl.gz... save 1.pkl.gz... done
compute 2.pkl.gz... save 2.pkl.gz... done
compute 3.pkl.gz... save 3.pkl.gz... done
compute 4.pkl.gz... save 4.pkl.gz... done
compute 5.pkl.gz... save 5.pkl.gz... done
compute 6.pkl.gz... save 6.pkl.gz... done
compute 7.pkl.gz... save 7.pkl.gz... done
compute 8.pkl.gz... save 8.pkl.gz... done
compute 9.pkl.gz... save 9.pkl.gz... done
compute 10.pkl.gz... save 10.pkl.gz... done
compute 11.pkl.gz... save 11.pkl.gz... done
compute 12.pkl.gz... save 12.pkl.gz... done
compute 13.pkl.gz... save 13.pkl.gz... done
compute 14.pkl.gz... save 14.pkl.gz... done
compute 15.pkl.gz... save 15.pkl.gz... done
compute 16.pkl.gz... save 16.pkl.gz... done
compute 17.pkl.gz... save 17.pkl.gz... done
compute 18.pkl.gz... save 18.pkl.gz... done
compute 19.pkl.gz... save 19.pkl.gz... done
compute 20.pkl.gz... save 20.pkl.gz... done
compute 21.pkl.gz... save 21.pkl.gz... done
compute 22.pkl.gz... save 22.pkl.gz... done
compute 23.pkl.gz... save 23.pkl.gz... done
compute 24.pkl.gz... save 24.pkl.gz... done
compute 25.pkl.gz... save 25.pkl.gz... done
compute 26.pkl.gz... save 26.pkl.gz... done
compute 27.pkl.gz... save 27.pkl.gz... done
compute 28.pkl.gz... save 28.pkl.gz... done
compute 29.pkl.gz... save 29.pkl.gz... done
compute 30.pkl.gz... save 30.pkl.gz... done
compute 31.pkl.gz... save 31.pkl.gz... done
compute 32.pkl.gz... save 32.pkl.gz... done
compute 33.pkl.gz... save 33.pkl.gz... done
compute 34.pkl.gz... save 34.pkl.gz... done
compute 35.pkl.gz... save 35.pkl.gz... done
compute 36.pkl.gz... save 36.pkl.gz... done
compute 37.pkl.gz... save 37.pkl.gz... done
compute 38.pkl.gz... save 38.pkl.gz... done
compute 39.pkl.gz... save 39.pkl.gz... done
compute 40.pkl.gz... save 40.pkl.gz... done
compute 41.pkl.gz... save 41.pkl.gz... done
compute 42.pkl.gz... save 42.pkl.gz... done
compute 43.pkl.gz... save 43.pkl.gz... done
[0|0] l1 loss: 1.57370 rescale loss: 0.94224 [units]
[0|250] l1 loss: 0.51090 rescale loss: 0.30590 [units]
[0|500] l1 loss: 0.50968 rescale loss: 0.30517 [units]
[0|750] l1 loss: 0.38311 rescale loss: 0.22938 [units]
Traceback (most recent call last):
  File "train.py", line 272, in <module>
    main(FLAGS, UNPARSED_ARGV)
  File "train.py", line 179, in main
    train_epoch(epoch, model, task_loss, train_loader, optimizer, scheduler, FLAGS)
  File "train.py", line 33, in train_epoch
    optimizer.zero_grad()
  File "/home/vwslz/anaconda3/envs/ml/lib/python3.8/site-packages/torch/optim/optimizer.py", line 184, in zero_grad
    if p.grad is not None:
  File "/home/vwslz/anaconda3/envs/ml/lib/python3.8/site-packages/torch/tensor.py", line 942, in grad
    from torch.overrides import has_torch_function, handle_torch_function
KeyboardInterrupt
