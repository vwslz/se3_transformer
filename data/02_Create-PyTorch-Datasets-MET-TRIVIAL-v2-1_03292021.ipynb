{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import prody as pdy\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "from sblu.rmsd import pwrmsd, calc_rmsd\n",
    "from sblu.cli.docking.cmd_cluster import cluster\n",
    "from scipy.spatial.distance import cdist, pdist, squareform\n",
    "from collections import OrderedDict, defaultdict\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON_DIR = '/gpfs/scratch/jakhil/residue-packing/out_redo_w_rot-cat_v4'\n",
    "CLEAN_PDB_DIR = '/gpfs/scratch/jakhil/CLEAN_PDB_03062021'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(json_file):\n",
    "    with open(json_file, 'r') as rf:\n",
    "        return json.load(rf)\n",
    "\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return super(NpEncoder, self).default(obj)\n",
    "\n",
    "def get_pdb(json_file):\n",
    "    pdb_name = os.path.basename(json_file).split('.')[0]\n",
    "    return os.path.abspath(f'{CLEAN_PDB_DIR}/{pdb_name}.pdb')\n",
    "\n",
    "def get_central_node(res_nums, ca_array, com, dist_thresh=100.0):\n",
    "    ca_array = [np.array(i) for i in ca_array]\n",
    "    for r, c in zip(res_nums, ca_array):\n",
    "        d = np.linalg.norm(c - com)\n",
    "        if d < dist_thresh:\n",
    "            dist_thresh = d\n",
    "            central_node = r\n",
    "    return central_node, dist_thresh\n",
    "\n",
    "\n",
    "def find_target_node(res_nums, protein, cluster_distance=20.0):\n",
    "    \"\"\"\n",
    "    We want to residues of interest, where each is seperated by at least a cluter distance from one another\n",
    "    (i.e., identify source nodes which are at do not overlap in any other graph)\n",
    "    \"\"\"\n",
    "    ca_atoms = protein.select('name CA and resnum {}'.format(' '.join([str(i) for i in roi_rn])))\n",
    "    N = ca_atoms.numAtoms()\n",
    "    \n",
    "    condensed_dists = pdist(ca_atoms._getCoordsets().reshape(N, -1), 'sqeuclidean')\n",
    "    rmsd_mat = squareform(np.sqrt(condensed_dists, condensed_dists))\n",
    "    # cluster\n",
    "    clusters = cluster(rmsd_mat, cluster_distance, 1, 100)\n",
    "    source_node = [roi_rn[i[0]] for i in clusters]\n",
    "    return source_node\n",
    "\n",
    "def find_chi_and_eg_coord(residue):\n",
    "    CHI_ATOM_MAP = {\n",
    "    'ARG' : 'CD', # 5 Rotamers\n",
    "    'ASN' : 'OD1', # 4 Rotamers\n",
    "    'ASP' : 'OD1', # 3 Rotamers\n",
    "    'CYS' : 'SG', # 2 Rotamers\n",
    "    'GLN' : 'CD', # 4 Rotamers\n",
    "    'GLU' : 'CD', # 5 Rotamers\n",
    "    'HIS' : 'ND1', # 5 Rotamers\n",
    "    'ILE' : 'CD1', # 4 Rotamers\n",
    "    'LEU' : 'CD1', # 3 Rotamers\n",
    "    'LYS' : 'CD', # 5 Rotamers\n",
    "    'MET' : 'SD', # 5 Rotamers\n",
    "    'PHE' : 'CD1', # 2 Rotamers\n",
    "    'SER' : 'OG', # 2 Rotamers\n",
    "    'THR' : 'OG1', # 2 Rotamers\n",
    "    'TRP' : 'CD1', # 6 Rotamers\n",
    "    'TYR' : 'CD1', # 2 Rotamers\n",
    "    'VAL' : 'CG1' # 2 Rotamers\n",
    "    }\n",
    "\n",
    "    EG_ATOM_MAP = {\n",
    "    'ARG' : 'NH2', # 5 Rotamers\n",
    "    'ASN' : 'ND2', # 4 Rotamers\n",
    "    'ASP' : 'OD2', # 3 Rotamers\n",
    "    'CYS' : 'SG', # 2 Rotamers\n",
    "    'GLN' : 'NE2', # 4 Rotamers\n",
    "    'GLU' : 'OE2', # 5 Rotamers\n",
    "    'HIS' : 'NE2', # 5 Rotamers\n",
    "    'ILE' : 'CD1', # 4 Rotamers\n",
    "    'LEU' : 'CD2', # 3 Rotamers\n",
    "    'LYS' : 'NZ', # 5 Rotamers\n",
    "    'MET' : 'CE', # 5 Rotamers\n",
    "    'PHE' : 'CZ', # 2 Rotamers\n",
    "    'SER' : 'OG', # 2 Rotamers\n",
    "    'THR' : 'OG1', # 2 Rotamers\n",
    "    'TRP' : 'CH2', # 6 Rotamers\n",
    "    'TYR' : 'CZ', # 2 Rotamers\n",
    "    'VAL' : 'CG2' # 2 Rotamers\n",
    "    }\n",
    "    res_name = residue.getResnames()[0]\n",
    "    if res_name not in ['ALA', 'PRO', 'GLY']:\n",
    "        chi_atom = str(CHI_ATOM_MAP[res_name])\n",
    "        eg_atom = str(EG_ATOM_MAP[res_name])\n",
    "    else:\n",
    "        chi_atom = 'CA'\n",
    "        eg_atom = 'CA'\n",
    "    return residue.select(f'name {chi_atom}').getCoords()[0], residue.select(f'name {eg_atom}').getCoords()[0]\n",
    "\n",
    "def print_ith_item(i):\n",
    "    for key in data['test'].keys():\n",
    "        print(key + \": \" + str(data['test'][key][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RES_TYPES = np.array(\n",
    "    ['ALA', 'ARG', 'ASN', 'ASP', 'CYS', 'GLN', 'GLU', 'GLY', 'HIS', 'ILE', 'LEU', 'LYS', 'MET', 'PHE', 'PRO',\n",
    "     'SER', 'THR', 'TRP', 'TYR', 'VAL'], dtype='str')\n",
    "\n",
    "MAX_NODES = 50\n",
    "MAX_EDGES = MAX_NODES - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsons = glob(f'{JSON_DIR}/*.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roi = 'MET' # residue of interest\n",
    "roi_rota_start = 42 # the first rotamer category of the roi\n",
    "roi_eg_start = 79 # the first end group category of the roi\n",
    "roi_rota_atom = 'SD' # chi2 terminal atom\n",
    "roi_eg_atom = 'CE' # doi: 10.1002/prot.23222\n",
    "\n",
    "RES_ID, RES_NAME, NUM_NODE, NUM_EDGE, PHI, PSI, X, Xn, Xc, CHI_COORD, EG_COORD, CHI_CATA, EG_CATA, EDGE = ([] for i in range(14))\n",
    "TARGET_CHI_CATA, TARGET_EG_CATA, TARGET_CHI_COORD, TARGET_EG_COORD = ([] for i in range(4))  # choose 1 to predict, but generating all\n",
    "for _json in jsons:\n",
    "    _data = read_json(os.path.abspath(_json))\n",
    "    df = pd.DataFrame.from_dict(_data)\n",
    "    roi_df = df[df['res_name'] == roi]\n",
    "    roi_rn = roi_df['res_num'].values\n",
    "    roi_ca = roi_df['ca_xyz'].values\n",
    "    roi_idx = roi_df.index\n",
    "    protein = pdy.parsePDB(get_pdb(_json)).select('heavy')\n",
    "    com = pdy.calcCenter(protein)\n",
    "    \n",
    "    if roi_df.shape[0] > 0:\n",
    "        target_nodes = find_target_node(roi_rn, protein)\n",
    "        for target_node in target_nodes:\n",
    "            d_target_to_center = round(pdy.calcDistance(protein.select(f'resnum {target_node}').getCoords(), com).min(), 1)\n",
    "            data = df[(df['res_num'] == int(target_node))]\n",
    "            \n",
    "            # Collect \"TARGET\" prefix values\n",
    "            target_chi_cata = data['rota_category'].values[0]\n",
    "            TARGET_CHI_CATA.append(abs(roi_rota_start - target_chi_cata))\n",
    "            target_eg_cata = data['end_group'].values[0]\n",
    "            TARGET_EG_CATA.append(abs(roi_eg_start - target_eg_cata))                      \n",
    "            res_id = [os.path.basename(_json).split('.')[0], str(target_node), str(target_chi_cata), str(target_eg_cata), str(d_target_to_center)]\n",
    "            RES_ID.append('_'.join(res_id))\n",
    "            \n",
    "            try:\n",
    "                TARGET_CHI_COORD.append(protein.select(f'resnum {target_node} and name {roi_rota_atom}').getCoords()[0]) \n",
    "            except:\n",
    "                TARGET_CHI_COORD.append(data['ca_xyz'].values[0])\n",
    "            try:\n",
    "                TARGET_EG_COORD.append(protein.select(f'resnum {target_node} and name {roi_eg_atom}').getCoords()[0])\n",
    "            except:\n",
    "                TARGET_EG_COORD.append(data['ca_xyz'].values[0])\n",
    "\n",
    "            # Collect Graph Data:\n",
    "            edge = []\n",
    "            d_mat = np.array(data['res_d_mat'].values[0][0])\n",
    "            neighbor_1_idx = [neighbor for neighbor in list(np.where(d_mat < 10.0)[0]) if neighbor != data.index[0]]\n",
    "\n",
    "            for neighbor in neighbor_1_idx:\n",
    "                edge.append([data.index[0], neighbor, 0])\n",
    "\n",
    "            # reformatting edges\n",
    "            list_node = []\n",
    "            for e in edge:\n",
    "                list_node.append(e[0])\n",
    "                list_node.append(e[1])\n",
    "            list_node = list(set(list_node))\n",
    "            neighbor_dict = dict(zip(list_node, [i for i in range(len(list_node))]))\n",
    "            re_indexed_edge = []\n",
    "            for e in edge:\n",
    "                e[0] = neighbor_dict[e[0]]\n",
    "                e[1] = neighbor_dict[e[1]]\n",
    "            num_edge = len(edge)\n",
    "            num_nodes = len(list_node)\n",
    "\n",
    "            # ensuring that edge dimension is the same for all graphs\n",
    "            norm_edge = np.zeros((MAX_EDGES, 3))\n",
    "            for i, v in enumerate(edge):\n",
    "                norm_edge[i] = v\n",
    "            EDGE.append(norm_edge)\n",
    "            NUM_EDGE.append(num_edge)\n",
    "            NUM_NODE.append(num_nodes)\n",
    "\n",
    "            # ensuring that features have same dimension across graphs\n",
    "            norm_x = np.zeros((MAX_NODES, 3))\n",
    "            norm_xc = np.zeros((MAX_NODES, 3))\n",
    "            norm_xn = np.zeros((MAX_NODES, 3))\n",
    "            norm_eg_coord = np.zeros((MAX_NODES, 3))\n",
    "            norm_chi_coord = np.zeros((MAX_NODES, 3))\n",
    "            norm_phi = np.zeros((MAX_NODES, 1))\n",
    "            norm_psi = np.zeros((MAX_NODES, 1))\n",
    "            norm_resname = np.zeros((MAX_NODES, 20), dtype=bool)\n",
    "            norm_chis = np.zeros((MAX_NODES, 1))\n",
    "            norm_egs = np.zeros((MAX_NODES, 1))\n",
    "\n",
    "            # getting rest of features for neighbors\n",
    "            _phi = df['phi'].values\n",
    "            _psi = df['psi'].values\n",
    "            _ca_xyz = df['ca_xyz'].values\n",
    "            _c_xyz = df['c_xyz'].values\n",
    "            _n_xyz = df['n_xyz'].values\n",
    "            _o_xyz = df['o_xyz'].values\n",
    "            _res_name = df['res_name'].values\n",
    "            _res_nums = df['res_num'].values\n",
    "            _chis = df['chis'].values\n",
    "            _res_cat = df['rota_category'].values\n",
    "            _eg_cat = df['end_group'].values\n",
    "            for idx, i in enumerate(list_node):\n",
    "                i = i.astype(int)\n",
    "                norm_x[idx] = [_ca_xyz[i][0], _ca_xyz[i][1], _ca_xyz[i][2]]\n",
    "                norm_xc[idx] = [_c_xyz[i][0], _c_xyz[i][1], _c_xyz[i][2]] # can be modified to reflect position relative to CA\n",
    "                norm_xn[idx] = [_n_xyz[i][0], _n_xyz[i][1], _n_xyz[i][2]] # can be modified to reflect position relative to CA\n",
    "                norm_phi[idx] = _phi[i]\n",
    "                norm_psi[idx] = _psi[i]\n",
    "                norm_resname[idx] = list(RES_TYPES == _res_name[i])\n",
    "                norm_chis[idx] = int(_res_cat[i])\n",
    "                norm_egs[idx] = int(_eg_cat[i])\n",
    "\n",
    "                try:\n",
    "                    chi_coord, eg_coord = find_chi_and_eg_coord(protein.select(f'resnum {_res_nums[i]}'))\n",
    "                    norm_chi_coord[idx] = chi_coord[0], chi_coord[1], chi_coord[2]\n",
    "                    norm_eg_coord[idx] = eg_coord[0], eg_coord[1], eg_coord[2]\n",
    "\n",
    "                except:\n",
    "                    norm_chi_coord[idx] = norm_x[idx]\n",
    "                    norm_eg_coord[idx] =  norm_x[idx]\n",
    "                \n",
    "                if i == data.index[0]:\n",
    "                    norm_chi_coord[idx] = 0, 0, 0\n",
    "                    norm_eg_coord[idx] = 0, 0, 0\n",
    "                    norm_chis[idx] = 0\n",
    "                    norm_egs[idx] = 0\n",
    "                    \n",
    "            PHI.append(norm_phi)\n",
    "            PSI.append(norm_psi)\n",
    "            RES_NAME.append(norm_resname)    \n",
    "            X.append(norm_x)\n",
    "            Xc.append(norm_xc)\n",
    "            Xn.append(norm_xn)\n",
    "            CHI_CATA.append(norm_chis)\n",
    "            EG_CATA.append(norm_egs)\n",
    "            CHI_COORD.append(norm_chi_coord)\n",
    "            EG_COORD.append(norm_eg_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_d = {\n",
    "    'res_id': RES_ID,\n",
    "    'num_node': NUM_NODE,\n",
    "    'num_edge': NUM_EDGE,\n",
    "    'target_cat': TARGET_CHI_CATA,\n",
    "#     'target_eg_cat': TARGET_EG_CATA,\n",
    "    'target_coord': TARGET_CHI_COORD,\n",
    "#     'target_eg_coord': TARGET_EG_COORD,\n",
    "    'chis': CHI_CATA,\n",
    "    'egs' : EG_CATA,\n",
    "    'chis_coord' : CHI_COORD,\n",
    "    'egs_coord' : EG_COORD,    \n",
    "    'x': X,\n",
    "    'x_c': Xc,\n",
    "    'x_n': Xn,\n",
    "    'one_hot': RES_NAME,\n",
    "    'phi': PHI,\n",
    "    'psi': PSI,\n",
    "    'edge': EDGE\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in data_d.keys():\n",
    "    print(i)\n",
    "    print(len(data_d[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(data_d)\n",
    "df['d_to_com'] = df['res_id'].apply(lambda x: float(x.split('_')[-1]))\n",
    "df = df.sort_values(by=['d_to_com'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CUTOFF = 1320\n",
    "df_1 = df[df['target_cat'] == 0][:CUTOFF].reset_index()\n",
    "df_2 = df[df['target_cat'] == 1][:CUTOFF].reset_index()\n",
    "df_3 = df[df['target_cat'] == 2][:CUTOFF].reset_index()\n",
    "df_4 = df[df['target_cat'] == 3][:CUTOFF].reset_index()\n",
    "df_5 = df[df['target_cat'] == 4][:CUTOFF].reset_index()\n",
    "df_6 = df[df['target_cat'] == 5][:CUTOFF].reset_index()\n",
    "df_7 = df[df['target_cat'] == 6][:CUTOFF].reset_index()\n",
    "df_8 = df[df['target_cat'] == 7][:CUTOFF].reset_index()\n",
    "df_9 = df[df['target_cat'] == 8][:CUTOFF].reset_index()\n",
    "print(df_1.shape,df_2.shape,df_3.shape,df_4.shape,df_5.shape,df_6.shape,df_7.shape,df_8.shape,df_9.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = pd.concat([df_1, df_2, df_3, df_4, df_5]).sort_index(kind='merge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = defaultdict(list)\n",
    "d = df_out.to_dict('list', into=dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dunbrack = {}\n",
    "\n",
    "data_dunbrack[\"train\"] = {}\n",
    "data_dunbrack[\"valid\"] = {}\n",
    "data_dunbrack[\"test\"] = {}\n",
    "\n",
    "split_train_valid = int(CUTOFF * 0.8)\n",
    "split_valid_test = int(CUTOFF * 0.9)\n",
    "\n",
    "for key in d.keys():\n",
    "    data_dunbrack[\"train\"][key] = d[key][0:split_train_valid]\n",
    "    data_dunbrack[\"valid\"][key] = d[key][split_train_valid:split_valid_test]\n",
    "    data_dunbrack[\"test\"][key] = d[key][split_valid_test:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(data_dunbrack, './11880-MET-TRIVIAL_EG-9_03302021.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load('./11880-MET-TRIVIAL_EG-9_03302021.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_ith_item(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = torch.load('/gpfs/scratch/jakhil/03252021_TYR-ROTA_10k.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
